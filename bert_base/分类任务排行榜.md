# 中文任务测评基准(CLUE benchmark)-排行榜 Leaderboard

## 分类任务(v1版本,正式版)

[数据来源](https://github.com/CLUEbenchmark/CLUE)
排行榜会定期更新 数据来源: www.CLUEbenchmarks.com 论文

| 模型              | Score | 参数  | AFQMC | TNEWS' | IFLYTEK' | CMNLI | CLUEWSC2020 | CSL   |
| ----------------- | ----- | ----- | ----- | ------ | -------- | ----- | ----------- | ----- |
| BERT-base         | 68.77 | 108M  | 73.70 | 56.58  | 60.29    | 79.69 | 62.0        | 80.36 |
| BERT-wwm-ext      | 68.75 | 108M  | 74.07 | 56.84  | 59.43    | 80.42 | 61.1        | 80.63 |
| ERNIE-base        |       | 68.55 | 108M  | 73.83  | 58.33    | 58.96 | 80.29       | 60.8  | 79.1 |
| RoBERTa-large     | 71.70 | 334M  | 74.02 | 57.86  | 62.55    | 81.70 | 72.7        | 81.36 |
| XLNet-mid         | 68.58 | 200M  | 70.50 | 56.24  | 57.85    | 81.25 | 64.4        | 81.26 |
| ALBERT-xxlarge7   | 1.04  | 235M  | 75.6  | 59.46  | 62.89    | 83.14 | 61.54       | 83.63 |
| ALBERT-xlarge     | 68.92 | 60M   | 69.96 | 57.36  | 59.50    | 81.13 | 64.34       | 81.20 |
| ALBERT-large      | 67.91 | 18M   | 74    | 55.16  | 57.00    | 78.77 | 62.24       | 80.30 |
| ALBERT-base       | 67.44 | 12M   | 72.55 | 55.06  | 56.58    | 77.58 | 64.34       | 78.5  |
| ALBERT-tiny       | 62.61 | 4M    | 69.92 | 53.35  | 48.71    | 70.61 | 58.5        | 74.56 |
| RoBERTa-wwm-ext   | 70.10 | 108M  | 74.04 | 56.94  | 60.31    | 80.51 | 67.8        | 81.0  |
| RoBERTa-wwm-large | 72.83 | 330M  | 76.55 | 58.61  | 62.98    | 82.12 | 74.6        | 82.13 |

注：

- AFQMC:蚂蚁语义相似度(Acc)
- TNEWS:文本分类(Acc)
- IFLYTEK:长文本分类(Acc)
- CMNLI: 自然语言推理中文版
- COPA: 因果推断
- WSC:CLUEWSC2020,即Winograd模式挑战中文版
- CSL: 中国科学文献数据集; Score总分是通过计算6个数据集得分平均值获得；
'代表对原数据集使用albert_tiny模型筛选后获得，数据集与原数据集不同,从而可能导致在这些数据集上albert_tiny表现略低.
